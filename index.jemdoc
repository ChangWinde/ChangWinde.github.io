# jemdoc: {index.html}, nofooter
# jemdoc: addcss{./config/jemdoc}
# jemdoc: addjs{./config/ga}
# jemdoc: addcss{./config/jemdoc.css}
==Fengshuo Bai

~~~
{}{img_left}{asserts/bio.jpg}{alt text}{180}{165}
PhD. Student\n 
Department of Computer Science and Engineering \n
Shanghai Jiao Tong University \n\n
Email: fengshuobai \[@\] sjtu \[DOT\] edu \[DOT\] cn \n
{{
<div style="display:flex; gap:10px; align-items:center;">
  <a href="https://github.com/ChangWinde" target="_blank">
    <img src="asserts/logo/github.png" alt="GitHub" style="width:27px;height:auto;border:0;">
  </a>
  <a href="https://scholar.google.com/citations?user=rzt0quQAAAAJ" target="_blank">
    <img src="asserts/logo/googlescholar.png" alt="GoogleScholar" style="width:22px;height:auto;border:0;">
  </a>
  <a href="https://x.com/FengshuoBai" target="_blank">
    <img src="asserts/logo/twitter.png" alt="Twitter" style="width:27px;height:auto;border:0;">
  </a>
</div>
}}
~~~

== Biography
I am currently a Ph.D. Student at [https://www.cs.sjtu.edu.cn/ Department of Computer Science and Engineering, Shanghai Jiao Tong University]
as well as a member of [https://pair-lab.com/ PAIR-Lab], co-advised by [https://www.yangyaodong.com/ Prof. Yaodong Yang] and [https://yingwen.io/ Prof. Ying Wen].
I am also selected into Wenjun Wu Honored Ph.D. Class in 2023, advised by [https://www.mvig.org Prof. Cewu Lu].
My research interest lies in Dexterous Manipulation, Preference-based RL and AI Alignment. If you would like to discuss about potential collaboration or common research interests, please do not hesitate to contact me.

== News üî•
üì¢ 2025.7 We have released our VLA survey titled ‚ÄúA Survey on Vision-Language-Action Models: An Action Tokenization Perspective.‚Äù \n
üì¢ 2025.6 Our paper has been accepted for oral presentation at the Artificial General Intelligence Conference (AGI-25)!

== Selected Papers
(* indicates equal contribution)\n
- [https://arxiv.org/abs/2507.01925 A Survey on Vision-Language-Action Models: An Action Tokenization Perspective] \n
  Yifan Zhong\*, *Fengshuo Bai*\*, Shaofei Cai, Xuchuan Huang, Zhang Chen, Xiaowei Zhang, Yuanfei Wang, Shaoyang Guo, Tianrui Guan, Ka Nam Lui, Zhiquan Qi, Yitao Liang, [https://cypypccpy.github.io/ Yuanpei Chen], [https://www.yangyaodong.com/ Yaodong Yang]
  {{
  <div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
    <a href="https://arxiv.org/abs/2507.01925" class="activate-button">
      Paper
    </a>
    <a href="https://arxiv.org/abs/2507.01925" class="activate-button">
      ArXiv
    </a>
    <a href="https://huggingface.co/papers/2507.01925" class="activate-button">
      HF
    </a>
    <a href="https://github.com/Psi-Robot/Awesome-VLA-Papers" class="activate-button">
      Github
    </a>
  </div>
  }}

- [https://arxiv.org/abs/2402.12907 Roadmap on Incentive Compatibility for Al Alignmentand Governance in Sociotechnical Systems] {{<span class="oral-tag">Oral</span>}}\n
  [https://zowiezhang.github.io/ Zhaowei Zhang], *Fengshuo Bai*, [https://github.com/ErlebnisW Mingzhi Wang], Haoyang Ye, [https://cdm1619.github.io/ Chengdong Ma], [https://www.yangyaodong.com/ Yaodong Yang] \n
  Artificial General Intelligence Conference (*AGI*), 2025 \n
  {{
  <div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
    <a href="https://arxiv.org/abs/2402.12907" class="activate-button">
      Paper
    </a>
    <a href="https://arxiv.org/abs/2402.12907" class="activate-button">
      ArXiv
    </a>
  </div>
  }}

- [https://arxiv.org/abs/2502.18423 Retrieval Dexterity: Efficient Object Retrieval in Clutters with Dexterous Hand] \n
  *Fengshuo Bai*, [https://github.com/Student-of-Holmes Yu Li], [https://bxzzcj.github.io/ Jie Chu], [https://openreview.net/profile?id=~Tawei_Chou1 Tawei Chou], [https://github.com/Zrc007 Runchuan Zhu], [https://yingwen.io/ Ying Wen], [https://www.yangyaodong.com/ Yaodong Yang], [https://cypypccpy.github.io/ Yuanpei Chen]
  {{
  <div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
    <a href="https://arxiv.org/abs/2502.18423" class="activate-button">
      Paper
    </a>
    <a href="https://arxiv.org/abs/2502.18423" class="activate-button">
      ArXiv
    </a>
    <a href="https://changwinde.github.io/RetrDex/" class="activate-button">
      Video
    </a>
    <a href="code_link" class="inactivate-button">
      Code
    </a>
  </div>
  }}

- [https://openreview.net/forum?id=f9w89OY2cp Amulet: ReAlignment During Test Time for Personalized Preference Adaptation of LLMs] \n
  [https://zowiezhang.github.io/ Zhaowei Zhang]\*, *Fengshuo Bai*\*, Qizhi Chen, [https://cdm1619.github.io/ Chengdong Ma], [https://github.com/ErlebnisW Mingzhi Wang], Haoran Sun, [https://zilongzheng.github.io/ Zilong Zheng], [https://www.yangyaodong.com/ Yaodong Yang] \n
  International Conference on Learning Representations (*ICLR*), 2025 \n
  {{
  <div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
    <a href="https://openreview.net/forum?id=f9w89OY2cp" class="activate-button">
      Paper
    </a>
    <a href="https://arxiv.org/abs/2502.19148" class="activate-button">
      ArXiv
    </a>
    <a href="https://zowiezhang.github.io/projects/Amulet/" class="activate-button">
      Video
    </a>
    <a href="https://github.com/zowiezhang/Amulet" class="activate-button">
      Code
    </a>
  </div>
  }}

- [https://aclanthology.org/2025.findings-naacl.223/ GRAIT: Gradient-Driven Refusal-Aware Instruction Tuning for Effective Hallucination Mitigation] \n
  [https://github.com/Zrc007 Runchuan Zhu], Xinke Jiang, Jiang Wu, Zhipeng ma, Jiahe Song, *Fengshuo Bai*, Dahua Lin, Lijun Wu, Conghui He \n
  Annual Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics (*NAACL*), 2025
  {{
  <div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
    <a href="https://aclanthology.org/2025.findings-naacl.223/" class="activate-button">
      Paper
    </a>
    <a href="https://arxiv.org/abs/2502.05911" class="activate-button">
      ArXiv
    </a>
  </div>
  }}

- [https://dl.acm.org/doi/10.5555/3709347.3743872 Œ≤-DQN: Improving Deep Q-Learning By Evolving the Behavior] {{<span class="oral-tag">Oral</span>}}\n
  [https://github.com/initial-h Hongming Zhang], *Fengshuo Bai*, Chenjun Xiao, Chao Gao, Bo Xu, [https://webdocs.cs.ualberta.ca/~mmueller/ Martin M√ºller]\n
  International Conference on Autonomous Agents and Multiagent Systems (*AAMAS*), 2025 \n
  {{
  <div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
    <a href="https://dl.acm.org/doi/10.5555/3709347.3743872" class="activate-button">
      Paper
    </a>
    <a href="https://arxiv.org/abs/2501.00913" class="activate-button">
      ArXiv
    </a>
    <a href="video_link" class="inactivate-button">
      Video
    </a>
    <a href="code_link" class="inactivate-button">
      Code
    </a>
  </div>
  }}

- [https://ojs.aaai.org/index.php/AAAI/article/view/33696 RAT: Adversarial Attacks on Deep Reinforcement Agents for Targeted Behaviors] {{<span class="oral-tag">Oral</span>}}\n
  *Fengshuo Bai*, [https://ryanliu112.github.io/ Runze Liu], [https://yalidu.github.io/ Yali Du], [https://yingwen.io/ Ying Wen], [https://www.yangyaodong.com/ Yaodong Yang]\n
  Proceedings of the AAAI Conference on Artificial Intelligence (*AAAI*), 2025 \n
  {{
  <div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/33696" class="activate-button">
      Paper
    </a>
    <a href="https://arxiv.org/abs/2412.10713" class="activate-button">
      ArXiv
    </a>
    <a href="https://sites.google.com/view/jj9uxjgmba5lr3g" class="activate-button">
      Video
    </a>
    <a href="https://github.com/ChangWinde/RAT" class="activate-button">
      Code
    </a>
  </div>
  }}

- [https://arxiv.org/abs/2405.18718 Efficient Model-agnostic Alignment via Bayesian Persuasion] \n
  *Fengshuo Bai*, [https://github.com/ErlebnisW Mingzhi Wang], [https://zowiezhang.github.io/ Zhaowei Zhang], [https://cby-pku.github.io/ Boyuan Chen], [https://marmotatzju.github.io/ Yinda Xu], [https://yingwen.io/ Ying Wen], [https://www.yangyaodong.com/ Yaodong Yang]\n
  {{
    <div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
      <a href="paper_link" class="inactivate-button">
        Paper
      </a>
      <a href="https://arxiv.org/abs/2405.18718" class="activate-button">
        ArXiv
      </a>
      <a href="video_link" class="inactivate-button">
        Video
      </a>
      <a href="code_link" class="inactivate-button">
        Code
      </a>
    </div>
  }}

- [https://arxiv.org/abs/2405.18688 Efficient Preference-based Reinforcement Learning via Aligned Experience Estimation] \n
  *Fengshuo Bai*, [https://ruizhaogit.github.io/ Rui Zhao], [https://github.com/initial-h Hongming Zhang], Sijia Cui, [https://yingwen.io/ Ying Wen], [https://www.yangyaodong.com/ Yaodong Yang], Bo Xu, [https://www.leihan.org/ Lei Han]\n
  {{
    <div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
      <a href="paper_link" class="inactivate-button">
        Paper
      </a>
      <a href="https://arxiv.org/abs/2405.18688" class="activate-button">
        ArXiv
      </a>
      <a href="video_link" class="inactivate-button">
        Video
      </a>
      <a href="code_link" class="inactivate-button">
        Code
      </a>
    </div>
  }}

- [https://openreview.net/forum?id=0urN0PnNDj PEARL: Zero-shot Cross-task Preference Alignment and Robust Reward Learning for Robotic Manipulation]\n
  [https://ryanliu112.github.io/ Runze Liu], [https://yalidu.github.io/ Yali Du], *Fengshuo Bai*, [https://dmksjfl.github.io/ Jiafei Lyu], Xiu Li \n
  Conference on International Conference on Machine Learning (*ICML*), 2024 \n
  {{
    <div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
      <a href="https://openreview.net/forum?id=0urN0PnNDj" class="activate-button">
        Paper
      </a>
      <a href="https://arxiv.org/abs/2306.03615" class="activate-button">
        ArXiv
      </a>
      <a href="https://sites.google.com/view/pearl-preference" class="activate-button">
        Video
      </a>
    </div>
  }}

- [https://arxiv.org/abs/2310.00378 Measuring Value Understanding in Language Models through Discriminator-Critique Gap] \n
  [https://zowiezhang.github.io/ Zhaowei Zhang],  *Fengshuo Bai*\*, Jun Gao\*, [https://www.yangyaodong.com/ Yaodong Yang] \n
  {{
    <div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
      <a href="paper_link" class="inactivate-button">
        Paper
      </a>
      <a href="https://arxiv.org/abs/2310.00378" class="activate-button">
        ArXiv
      </a>
      <a href="video_link" class="inactivate-button">
        Video
      </a>
      <a href="code_link" class="inactivate-button">
        Code
      </a>
    </div>
  }}

- [https://ojs.aaai.org/index.php/AAAI/article/view/25825 PiCor: multi-task deep reinforcement learning with policy correction] {{<span class="oral-tag">Oral</span>}}\n
  *Fengshuo Bai*, [https://github.com/initial-h Hongming Zhang], Tianyang Tao, Zhiheng Wu, Yanna Wang, Bo Xu \n
  Proceedings of the AAAI Conference on Artificial Intelligence (*AAAI*), 2023 \n
  {{
    <div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
      <a href="https://ojs.aaai.org/index.php/AAAI/article/view/25825" class="activate-button">
        Paper
      </a>
      <a href="https://github.com/ChangWinde/PiCor" class="activate-button">
        Code
      </a>
    </div>
  }}

- [https://proceedings.neurips.cc/paper%5files/paper/2022/hash/8be9c134bb193d8bd3827d4df8488228-Abstract-Conference.html Meta-reward-net: Implicitly differentiable reward learning for preference-based reinforcement learning]\n
  [https://ryanliu112.github.io/ Runze Liu], *Fengshuo Bai*, [https://yalidu.github.io/ Yali Du], [https://www.yangyaodong.com/ Yaodong Yang] \n
  Conference on Neural Information Processing Systems (*NeurIPS*), 2022 \n
  {{
  <div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
    <a href="https://proceedings.neurips.cc/paper%5Ffiles/paper/2022/hash/8be9c134bb193d8bd3827d4df8488228-Abstract-Conference.html" class="activate-button">
      Paper
    </a>
    <a href="https://sites.google.com/view/meta-reward-net" class="activate-button">
      Video
    </a>
    <a href="https://github.com/RyanLiu112/MRN" class="activate-button">
      Code
    </a>
  </div>
  }}

=== Experiences
- Institute for AI, Peking University (Jan 2022 - Oct 2022)\n
  Research on algorithms of Reinforcement Learning from the Human Feedback.\n
  Supervisor: [https://yalidu.github.io/ Dr. Yali Du], [https://www.yangyaodong.com/ Dr. Yaodong Yang]

=== Honors & Awards
- Pacemaker to Merit Student, 2018.09
- President Scholarship of Southeast University, 2018.09
- China National Scholarship, 2017.09

=== Competitions
- Sliver Prize (25/1178), *Kaggle* Lux AI Challenge, 2021.12
- Third (Intro), 7th (Research) *NeurIPS* 2021 MineRL Diamond Competition, 2021.10
- 14th, *IJCAI* 2020 Mahjong Artificial Intelligence Competition, 2021.01

=== Services
I was a reviewer / PC member of conferences:\n
*DAI 2023-2024* \n
*AAMAS 2024-2025* \n
*NeurIPS 2024-2025* \n
*ICLR 2025* \n
*AAAI 2025* \n
*ICML 2025* \n
*IJCAI 2025* \n
*IROS 2025*


=== Visitors
~~~
{}{raw}
<div style="transform: scale(1.0); transform-origin: 90% 0; display: flex; justify-content: center; width: 100%;">
<script type='text/javascript' id='clustrmaps' src='https://cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=qVXmqI50LHdDWdRzTqaNyq8Uf3l13TYqDyI3oLM6wo4'></script>
</div>
~~~