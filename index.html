<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="stylesheet" href="./config/jemdoc.css" type="text/css" />
<link rel="stylesheet" href="./config/jemdoc.css" type="text/css" />
<script src="./config/ga.js" type="text/javascript"></script>
<title>Fengshuo Bai</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Fengshuo Bai</h1>
</div>
<table class="imgtable"><tr><td>
<img src="asserts/bio.jpg" alt="alt text" width="180px" height="165px" />&nbsp;</td>
<td align="left"><p>PhD. Student<br /> 
Department of Computer Science and Engineering <br />
Shanghai Jiao Tong University <br /><br />
Email: fengshuobai [@] sjtu [DOT] edu [DOT] cn <br />
</p>
<p>
<div style="display:flex; gap:10px; align-items:center;">
<a href="https://github.com/ChangWinde" target="<u>blank">
<img src="asserts/logo/github.png" alt="GitHub" style="width:27px;height:auto;border:0;">
</a>
<a href="https://scholar.google.com/citations?user=rzt0quQAAAAJ" target="</u>blank">
<img src="asserts/logo/googlescholar.png" alt="GoogleScholar" style="width:22px;height:auto;border:0;">
</a>
<a href="https://x.com/FengshuoBai" target="_blank">
<img src="asserts/logo/twitter.png" alt="Twitter" style="width:27px;height:auto;border:0;">
</a>
</div>

</p>
</td></tr></table>
<h2>Biography</h2>
<p>I am currently a Ph.D. Student at <a href="https://www.cs.sjtu.edu.cn/" target=&ldquo;blank&rdquo;>Department of Computer Science and Engineering, Shanghai Jiao Tong University</a>
as well as a member of <a href="https://pair-lab.com/" target=&ldquo;blank&rdquo;>PAIR-Lab</a>, co-advised by <a href="https://www.yangyaodong.com/" target=&ldquo;blank&rdquo;>Prof. Yaodong Yang</a> and <a href="https://yingwen.io/" target=&ldquo;blank&rdquo;>Prof. Ying Wen</a>.
I am also selected into Wenjun Wu Honored Ph.D. Class in 2023, advised by <a href="https://www.mvig.org" target=&ldquo;blank&rdquo;>Prof. Cewu Lu</a>.
My research interest lies in Dexterous Manipulation, Preference-based RL and AI Alignment. If you would like to discuss about potential collaboration or common research interests, please do not hesitate to contact me.
</p>
<h2>News üî•</h2>
<p>üì¢ 2025.7 We have released our VLA survey titled ‚ÄúA Survey on Vision-Language-Action Models: An Action Tokenization Perspective.‚Äù <br />
üì¢ 2025.6 Our paper has been accepted for oral presentation at the Artificial General Intelligence Conference (AGI-25)!
</p>
<h2>Selected Papers</h2>
<p>(* indicates equal contribution)<br />
</p>
<ul>
<li><p><a href="https://arxiv.org/abs/2507.01925" target=&ldquo;blank&rdquo;>A Survey on Vision-Language-Action Models: An Action Tokenization Perspective</a> <br />
Yifan Zhong*, <b>Fengshuo Bai</b>*, Shaofei Cai, Xuchuan Huang, Zhang Chen, Xiaowei Zhang, Yuanfei Wang, Shaoyang Guo, Tianrui Guan, Ka Nam Lui, Zhiquan Qi, Yitao Liang, <a href="https://cypypccpy.github.io/" target=&ldquo;blank&rdquo;>Yuanpei Chen</a>, <a href="https://www.yangyaodong.com/" target=&ldquo;blank&rdquo;>Yaodong Yang</a>
</p>
</li>
</ul>
<p>
<div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
<a href="https://arxiv.org/abs/2507.01925" class="activate-button">
Paper
</a>
<a href="https://arxiv.org/abs/2507.01925" class="activate-button">
ArXiv
</a>
<a href="https://huggingface.co/papers/2507.01925" class="activate-button">
HF
</a>
<a href="https://github.com/Psi-Robot/Awesome-VLA-Papers" class="activate-button">
Github
</a>
</div>

</p>
<ul>
<li><p><a href="https://arxiv.org/abs/2402.12907" target=&ldquo;blank&rdquo;>Roadmap on Incentive Compatibility for Al Alignmentand Governance in Sociotechnical Systems</a> <span class="oral-tag">Oral</span><br />
<a href="https://zowiezhang.github.io/" target=&ldquo;blank&rdquo;>Zhaowei Zhang</a>, <b>Fengshuo Bai</b>, <a href="https://github.com/ErlebnisW" target=&ldquo;blank&rdquo;>Mingzhi Wang</a>, Haoyang Ye, <a href="https://cdm1619.github.io/" target=&ldquo;blank&rdquo;>Chengdong Ma</a>, <a href="https://www.yangyaodong.com/" target=&ldquo;blank&rdquo;>Yaodong Yang</a> <br />
Artificial General Intelligence Conference (<b>AGI</b>), 2025 <br />
</p>
</li>
</ul>
<p>
<div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
<a href="https://arxiv.org/abs/2402.12907" class="activate-button">
Paper
</a>
<a href="https://arxiv.org/abs/2402.12907" class="activate-button">
ArXiv
</a>
</div>

</p>
<ul>
<li><p><a href="https://arxiv.org/abs/2502.18423" target=&ldquo;blank&rdquo;>Retrieval Dexterity: Efficient Object Retrieval in Clutters with Dexterous Hand</a> <br />
<b>Fengshuo Bai</b>, <a href="https://github.com/Student-of-Holmes" target=&ldquo;blank&rdquo;>Yu Li</a>, <a href="https://bxzzcj.github.io/" target=&ldquo;blank&rdquo;>Jie Chu</a>, <a href="https://openreview.net/profile?id=~Tawei_Chou1" target=&ldquo;blank&rdquo;>Tawei Chou</a>, <a href="https://github.com/Zrc007" target=&ldquo;blank&rdquo;>Runchuan Zhu</a>, <a href="https://yingwen.io/" target=&ldquo;blank&rdquo;>Ying Wen</a>, <a href="https://www.yangyaodong.com/" target=&ldquo;blank&rdquo;>Yaodong Yang</a>, <a href="https://cypypccpy.github.io/" target=&ldquo;blank&rdquo;>Yuanpei Chen</a>
</p>
</li>
</ul>
<p>
<div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
<a href="https://arxiv.org/abs/2502.18423" class="activate-button">
Paper
</a>
<a href="https://arxiv.org/abs/2502.18423" class="activate-button">
ArXiv
</a>
<a href="https://changwinde.github.io/RetrDex/" class="activate-button">
Video
</a>
<a href="code_link" class="inactivate-button">
Code
</a>
</div>

</p>
<ul>
<li><p><a href="https://openreview.net/forum?id=f9w89OY2cp" target=&ldquo;blank&rdquo;>Amulet: ReAlignment During Test Time for Personalized Preference Adaptation of LLMs</a> <br />
<a href="https://zowiezhang.github.io/" target=&ldquo;blank&rdquo;>Zhaowei Zhang</a>*, <b>Fengshuo Bai</b>*, Qizhi Chen, <a href="https://cdm1619.github.io/" target=&ldquo;blank&rdquo;>Chengdong Ma</a>, <a href="https://github.com/ErlebnisW" target=&ldquo;blank&rdquo;>Mingzhi Wang</a>, Haoran Sun, <a href="https://zilongzheng.github.io/" target=&ldquo;blank&rdquo;>Zilong Zheng</a>, <a href="https://www.yangyaodong.com/" target=&ldquo;blank&rdquo;>Yaodong Yang</a> <br />
International Conference on Learning Representations (<b>ICLR</b>), 2025 <br />
</p>
</li>
</ul>
<p>
<div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
<a href="https://openreview.net/forum?id=f9w89OY2cp" class="activate-button">
Paper
</a>
<a href="https://arxiv.org/abs/2502.19148" class="activate-button">
ArXiv
</a>
<a href="https://zowiezhang.github.io/projects/Amulet/" class="activate-button">
Video
</a>
<a href="https://github.com/zowiezhang/Amulet" class="activate-button">
Code
</a>
</div>

</p>
<ul>
<li><p><a href="https://aclanthology.org/2025.findings-naacl.223/" target=&ldquo;blank&rdquo;>GRAIT: Gradient-Driven Refusal-Aware Instruction Tuning for Effective Hallucination Mitigation</a> <br />
<a href="https://github.com/Zrc007" target=&ldquo;blank&rdquo;>Runchuan Zhu</a>, Xinke Jiang, Jiang Wu, Zhipeng ma, Jiahe Song, <b>Fengshuo Bai</b>, Dahua Lin, Lijun Wu, Conghui He <br />
Annual Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics (<b>NAACL</b>), 2025
</p>
</li>
</ul>
<p>
<div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
<a href="https://aclanthology.org/2025.findings-naacl.223/" class="activate-button">
Paper
</a>
<a href="https://arxiv.org/abs/2502.05911" class="activate-button">
ArXiv
</a>
</div>

</p>
<ul>
<li><p><a href="https://dl.acm.org/doi/10.5555/3709347.3743872" target=&ldquo;blank&rdquo;>Œ≤-DQN: Improving Deep Q-Learning By Evolving the Behavior</a> <span class="oral-tag">Oral</span><br />
<a href="https://github.com/initial-h" target=&ldquo;blank&rdquo;>Hongming Zhang</a>, <b>Fengshuo Bai</b>, Chenjun Xiao, Chao Gao, Bo Xu, <a href="https://webdocs.cs.ualberta.ca/~mmueller/" target=&ldquo;blank&rdquo;>Martin M√ºller</a><br />
International Conference on Autonomous Agents and Multiagent Systems (<b>AAMAS</b>), 2025 <br />
</p>
</li>
</ul>
<p>
<div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
<a href="https://dl.acm.org/doi/10.5555/3709347.3743872" class="activate-button">
Paper
</a>
<a href="https://arxiv.org/abs/2501.00913" class="activate-button">
ArXiv
</a>
<a href="video<u>link" class="inactivate-button">
Video
</a>
<a href="code</u>link" class="inactivate-button">
Code
</a>
</div>

</p>
<ul>
<li><p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/33696" target=&ldquo;blank&rdquo;>RAT: Adversarial Attacks on Deep Reinforcement Agents for Targeted Behaviors</a> <span class="oral-tag">Oral</span><br />
<b>Fengshuo Bai</b>, <a href="https://ryanliu112.github.io/" target=&ldquo;blank&rdquo;>Runze Liu</a>, <a href="https://yalidu.github.io/" target=&ldquo;blank&rdquo;>Yali Du</a>, <a href="https://yingwen.io/" target=&ldquo;blank&rdquo;>Ying Wen</a>, <a href="https://www.yangyaodong.com/" target=&ldquo;blank&rdquo;>Yaodong Yang</a><br />
Proceedings of the AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2025 <br />
</p>
</li>
</ul>
<p>
<div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
<a href="https://ojs.aaai.org/index.php/AAAI/article/view/33696" class="activate-button">
Paper
</a>
<a href="https://arxiv.org/abs/2412.10713" class="activate-button">
ArXiv
</a>
<a href="https://sites.google.com/view/jj9uxjgmba5lr3g" class="activate-button">
Video
</a>
<a href="https://github.com/ChangWinde/RAT" class="activate-button">
Code
</a>
</div>

</p>
<ul>
<li><p><a href="https://arxiv.org/abs/2405.18718" target=&ldquo;blank&rdquo;>Efficient Model-agnostic Alignment via Bayesian Persuasion</a> <br />
<b>Fengshuo Bai</b>, <a href="https://github.com/ErlebnisW" target=&ldquo;blank&rdquo;>Mingzhi Wang</a>, <a href="https://zowiezhang.github.io/" target=&ldquo;blank&rdquo;>Zhaowei Zhang</a>, <a href="https://cby-pku.github.io/" target=&ldquo;blank&rdquo;>Boyuan Chen</a>, <a href="https://marmotatzju.github.io/" target=&ldquo;blank&rdquo;>Yinda Xu</a>, <a href="https://yingwen.io/" target=&ldquo;blank&rdquo;>Ying Wen</a>, <a href="https://www.yangyaodong.com/" target=&ldquo;blank&rdquo;>Yaodong Yang</a><br />
</p>
</li>
</ul>
<p>
<div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
<a href="paper<u>link" class="inactivate-button">
Paper
</a>
<a href="https://arxiv.org/abs/2405.18718" class="activate-button">
ArXiv
</a>
<a href="video</u>link" class="inactivate-button">
Video
</a>
<a href="code_link" class="inactivate-button">
Code
</a>
</div>

</p>
<ul>
<li><p><a href="https://arxiv.org/abs/2405.18688" target=&ldquo;blank&rdquo;>Efficient Preference-based Reinforcement Learning via Aligned Experience Estimation</a> <br />
<b>Fengshuo Bai</b>, <a href="https://ruizhaogit.github.io/" target=&ldquo;blank&rdquo;>Rui Zhao</a>, <a href="https://github.com/initial-h" target=&ldquo;blank&rdquo;>Hongming Zhang</a>, Sijia Cui, <a href="https://yingwen.io/" target=&ldquo;blank&rdquo;>Ying Wen</a>, <a href="https://www.yangyaodong.com/" target=&ldquo;blank&rdquo;>Yaodong Yang</a>, Bo Xu, <a href="https://www.leihan.org/" target=&ldquo;blank&rdquo;>Lei Han</a><br />
</p>
</li>
</ul>
<p>
<div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
<a href="paper<u>link" class="inactivate-button">
Paper
</a>
<a href="https://arxiv.org/abs/2405.18688" class="activate-button">
ArXiv
</a>
<a href="video</u>link" class="inactivate-button">
Video
</a>
<a href="code_link" class="inactivate-button">
Code
</a>
</div>

</p>
<ul>
<li><p><a href="https://openreview.net/forum?id=0urN0PnNDj" target=&ldquo;blank&rdquo;>PEARL: Zero-shot Cross-task Preference Alignment and Robust Reward Learning for Robotic Manipulation</a><br />
<a href="https://ryanliu112.github.io/" target=&ldquo;blank&rdquo;>Runze Liu</a>, <a href="https://yalidu.github.io/" target=&ldquo;blank&rdquo;>Yali Du</a>, <b>Fengshuo Bai</b>, <a href="https://dmksjfl.github.io/" target=&ldquo;blank&rdquo;>Jiafei Lyu</a>, Xiu Li <br />
Conference on International Conference on Machine Learning (<b>ICML</b>), 2024 <br />
</p>
</li>
</ul>
<p>
<div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
<a href="https://openreview.net/forum?id=0urN0PnNDj" class="activate-button">
Paper
</a>
<a href="https://arxiv.org/abs/2306.03615" class="activate-button">
ArXiv
</a>
<a href="https://sites.google.com/view/pearl-preference" class="activate-button">
Video
</a>
</div>

</p>
<ul>
<li><p><a href="https://arxiv.org/abs/2310.00378" target=&ldquo;blank&rdquo;>Measuring Value Understanding in Language Models through Discriminator-Critique Gap</a> <br />
<a href="https://zowiezhang.github.io/" target=&ldquo;blank&rdquo;>Zhaowei Zhang</a>,  <b>Fengshuo Bai</b>*, Jun Gao*, <a href="https://www.yangyaodong.com/" target=&ldquo;blank&rdquo;>Yaodong Yang</a> <br />
</p>
</li>
</ul>
<p>
<div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
<a href="paper<u>link" class="inactivate-button">
Paper
</a>
<a href="https://arxiv.org/abs/2310.00378" class="activate-button">
ArXiv
</a>
<a href="video</u>link" class="inactivate-button">
Video
</a>
<a href="code_link" class="inactivate-button">
Code
</a>
</div>

</p>
<ul>
<li><p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/25825" target=&ldquo;blank&rdquo;>PiCor: multi-task deep reinforcement learning with policy correction</a> <span class="oral-tag">Oral</span><br />
<b>Fengshuo Bai</b>, <a href="https://github.com/initial-h" target=&ldquo;blank&rdquo;>Hongming Zhang</a>, Tianyang Tao, Zhiheng Wu, Yanna Wang, Bo Xu <br />
Proceedings of the AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2023 <br />
</p>
</li>
</ul>
<p>
<div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
<a href="https://ojs.aaai.org/index.php/AAAI/article/view/25825" class="activate-button">
Paper
</a>
<a href="https://github.com/ChangWinde/PiCor" class="activate-button">
Code
</a>
</div>

</p>
<ul>
<li><p><a href="https://proceedings.neurips.cc/paper%5files/paper/2022/hash/8be9c134bb193d8bd3827d4df8488228-Abstract-Conference.html" target=&ldquo;blank&rdquo;>Meta-reward-net: Implicitly differentiable reward learning for preference-based reinforcement learning</a><br />
<a href="https://ryanliu112.github.io/" target=&ldquo;blank&rdquo;>Runze Liu</a>, <b>Fengshuo Bai</b>, <a href="https://yalidu.github.io/" target=&ldquo;blank&rdquo;>Yali Du</a>, <a href="https://www.yangyaodong.com/" target=&ldquo;blank&rdquo;>Yaodong Yang</a> <br />
Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2022 <br />
</p>
</li>
</ul>
<p>
<div style="display:flex; gap:4px; margin-left:40px;; margin-top:-10px;">
<a href="https://proceedings.neurips.cc/paper%5Ffiles/paper/2022/hash/8be9c134bb193d8bd3827d4df8488228-Abstract-Conference.html" class="activate-button">
Paper
</a>
<a href="https://sites.google.com/view/meta-reward-net" class="activate-button">
Video
</a>
<a href="https://github.com/RyanLiu112/MRN" class="activate-button">
Code
</a>
</div>

</p>
<h3>Experiences</h3>
<ul>
<li><p>Institute for AI, Peking University (Jan 2022 - Oct 2022)<br />
Research on algorithms of Reinforcement Learning from the Human Feedback.<br />
Supervisor: <a href="https://yalidu.github.io/" target=&ldquo;blank&rdquo;>Dr. Yali Du</a>, <a href="https://www.yangyaodong.com/" target=&ldquo;blank&rdquo;>Dr. Yaodong Yang</a>
</p>
</li>
</ul>
<h3>Honors &amp; Awards</h3>
<ul>
<li><p>Pacemaker to Merit Student, 2018.09
</p>
</li>
<li><p>President Scholarship of Southeast University, 2018.09
</p>
</li>
<li><p>China National Scholarship, 2017.09
</p>
</li>
</ul>
<h3>Competitions</h3>
<ul>
<li><p>Sliver Prize (25/1178), <b>Kaggle</b> Lux AI Challenge, 2021.12
</p>
</li>
<li><p>Third (Intro), 7th (Research) <b>NeurIPS</b> 2021 MineRL Diamond Competition, 2021.10
</p>
</li>
<li><p>14th, <b>IJCAI</b> 2020 Mahjong Artificial Intelligence Competition, 2021.01
</p>
</li>
</ul>
<h3>Services</h3>
<p>I was a reviewer / PC member of conferences:<br />
<b>DAI 2023-2024</b> <br />
<b>AAMAS 2024-2025</b> <br />
<b>NeurIPS 2024-2025</b> <br />
<b>ICLR 2025</b> <br />
<b>AAAI 2025</b> <br />
<b>ICML 2025</b> <br />
<b>IJCAI 2025</b> <br />
<b>IROS 2025</b>
</p>
<h3>Visitors</h3>
<div style="transform: scale(1.0); transform-origin: 90% 0; display: flex; justify-content: center; width: 100%;">
<script type='text/javascript' id='clustrmaps' src='https://cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=qVXmqI50LHdDWdRzTqaNyq8Uf3l13TYqDyI3oLM6wo4'></script>
</div>
</div>
</body>
</html>
